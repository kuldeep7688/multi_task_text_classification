{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, BertConfig, BertModel, BertPreTrainedModel\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCT_LABELS = [\n",
    "    'Vehicle loan or lease', 'Student loan', 'Consumer Loan'\n",
    "]\n",
    "\n",
    "ISSUE_LABELS = [\n",
    "    'Managing the loan or lease', 'Problems at the end of the loan or lease', 'Struggling to pay your loan', 'Getting a loan or lease', 'Dealing with your lender or servicer', 'Incorrect information on your report', 'Problems when you are unable to pay', 'Taking out the loan or lease'\n",
    "]\n",
    "\n",
    "PRODUCT_LABELS_TO_IDX = {\n",
    "    i : idx\n",
    "    for idx, i in enumerate(PRODUCT_LABELS)\n",
    "}\n",
    "\n",
    "IDX_TO_PRODUCT_LABELS = {\n",
    "    i: j\n",
    "    for j, i in PRODUCT_LABELS_TO_IDX.items()\n",
    "}\n",
    "\n",
    "ISSUE_LABELS_TO_IDX = {\n",
    "    i : idx\n",
    "    for idx, i in enumerate(ISSUE_LABELS)\n",
    "}\n",
    "\n",
    "IDX_TO_ISSUE_LABELS = {\n",
    "    i: j\n",
    "    for j, i in ISSUE_LABELS_TO_IDX.items()\n",
    "}\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "PRETRAINED_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_TRAIN_EPOCHS = 10\n",
    "FINETUNED_MODEL_PATH = './results/experiment_2024-06-19_20-51-41/checkpoint-17000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskSentencePrediction(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_product_labels, num_issue_labels):\n",
    "        super().__init__(config)\n",
    "        self.num_product_labels = num_product_labels\n",
    "        self.num_issue_labels = num_issue_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        self.product_classifier = nn.Linear(config.hidden_size, num_product_labels)\n",
    "        self.issue_classifier = nn.Linear(config.hidden_size, num_issue_labels)\n",
    "\n",
    "        classifier_dropout = config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        \n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self, input_ids, attention_mask=None, token_type_ids=None, \n",
    "            product_label=None, issue_label=None \n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids, attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_outputs = self.dropout(outputs[1])\n",
    "        \n",
    "        logits_product = self.product_classifier(pooled_outputs)\n",
    "        logits_issue = self.issue_classifier(pooled_outputs)\n",
    "\n",
    "        loss = None\n",
    "        if product_label != None and issue_label != None:\n",
    "            loss_fct1 = nn.CrossEntropyLoss()\n",
    "            loss_fct2 = nn.CrossEntropyLoss()\n",
    "\n",
    "            loss = loss_fct1(\n",
    "                logits_product.view(-1, self.num_product_labels),\n",
    "                product_label.view(-1)\n",
    "            ) + loss_fct2(\n",
    "                logits_issue.view(-1, self.num_issue_labels),\n",
    "                issue_label.view(-1)\n",
    "            )\n",
    "        \n",
    "        return (loss, logits_product, logits_issue) if loss is not None else (logits_product, logits_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "# initializing Config and Tokenizer\n",
    "BERT_CONFIG = BertConfig.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully...\n"
     ]
    }
   ],
   "source": [
    "# loading model \n",
    "model = MultiTaskSentencePrediction.from_pretrained(\n",
    "    FINETUNED_MODEL_PATH, config=BERT_CONFIG,\n",
    "    num_product_labels=len(PRODUCT_LABELS), num_issue_labels=len(ISSUE_LABELS)\n",
    ")\n",
    "print('Model loaded successfully...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_on_dataframe(df, model):\n",
    "    predictions_product = []\n",
    "    predictions_issue = []\n",
    "\n",
    "    probability_product = []\n",
    "    probability_issue = []\n",
    "\n",
    "    for text in tqdm(df.consumer_complaint, total=df.shape[0]):\n",
    "        if len(text) > 0:\n",
    "            inputs_to_model = TOKENIZER(text, padding=True, truncation=True)\n",
    "            inputs_to_model['input_ids'] = torch.tensor([inputs_to_model['input_ids'][:MAX_SEQUENCE_LENGTH]])\n",
    "            # inputs_to_model['token_type_ids'] = torch.tensor([inputs_to_model['token_type_ids'][:MAX_SEQUENCE_LENGTH]])\n",
    "            inputs_to_model['attention_mask'] = torch.tensor([inputs_to_model['attention_mask'][:MAX_SEQUENCE_LENGTH]])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model_outputs = model(**inputs_to_model)\n",
    "            \n",
    "            overall_prob, overall_pred = torch.max(torch.softmax(model_outputs[0], dim=1), dim=1)\n",
    "            second_prob, second_pred = torch.max(torch.softmax(model_outputs[1], dim=1), dim=1)\n",
    "            predictions_product.append(\n",
    "                IDX_TO_PRODUCT_LABELS[overall_pred.item()]\n",
    "            )\n",
    "            predictions_issue.append(\n",
    "                IDX_TO_ISSUE_LABELS[second_pred.item()]\n",
    "            )\n",
    "\n",
    "            probability_product.append(\n",
    "                round(overall_prob[0].item(), 3)\n",
    "            )\n",
    "            probability_issue.append(\n",
    "                round(second_prob[0].item(), 3)\n",
    "            )\n",
    "        else:\n",
    "            predictions_product.append(None)\n",
    "            predictions_issue.append(None)\n",
    "\n",
    "            probability_product.append(None)\n",
    "            probability_issue.append(None)\n",
    "\n",
    "\n",
    "    df['product_predictions'] = predictions_product\n",
    "    df['product_pred_probability'] = probability_product\n",
    "    df['issue_predictions'] = predictions_issue\n",
    "    df['issue_pred_probability'] = probability_issue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_data.csv')\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_predictions_on_dataframe(test_df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Product Prediction : 0.8350117423827834  | Issue Prediction : 0.5478804429185374\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'F1 Score for Product Prediction : {}  | Issue Prediction : {}'.format(\n",
    "        f1_score(y_true=test_df['product'], y_pred=test_df.product_predictions, average=\"weighted\"),\n",
    "        f1_score(y_true=test_df.issue, y_pred=test_df.issue_predictions, average='weighted')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Product Prediction : 0.8415  | Issue Prediction : 0.575\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Accuracy Score for Product Prediction : {}  | Issue Prediction : {}'.format(\n",
    "        accuracy_score(y_true=test_df['product'], y_pred=test_df.product_predictions),\n",
    "        accuracy_score(y_true=test_df.issue, y_pred=test_df.issue_predictions)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
